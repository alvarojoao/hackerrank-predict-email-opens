{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import time\n",
    "from datetime import date\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "def saveFileForSubmission(predicted_lables,custonFileName='submission.csv',customHeader=''):\n",
    "    result = np.c_[predicted_lables]\n",
    "\n",
    "    np.savetxt(custonFileName, \n",
    "           result.astype(int), \n",
    "           delimiter=',', \n",
    "           header = customHeader, \n",
    "           comments = '', \n",
    "           fmt='%u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm(dataframe,variable):\n",
    "    mean = dataframe[variable].mean()\n",
    "    max_val = dataframe[variable].max()\n",
    "    min_val = dataframe[variable].min()\n",
    "    dataframe[variable] = dataframe[variable].apply(lambda x: (x - mean) / (max_val -min_val+0.0001))\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preProcessData(dataframe,train=True):\n",
    "    mailTypes = ['mail_type_1', 'mail_type_2', 'mail_type_3', 'mail_type_4']\n",
    "    mailCategories = ['mail_category_1', 'mail_category_10', 'mail_category_11',\n",
    "                    'mail_category_12', 'mail_category_13', 'mail_category_14',\n",
    "                    'mail_category_15', 'mail_category_16', 'mail_category_17',\n",
    "                    'mail_category_18', 'mail_category_2', 'mail_category_3',\n",
    "                    'mail_category_4', 'mail_category_5', 'mail_category_6',\n",
    "                    'mail_category_7', 'mail_category_8', 'mail_category_9']\n",
    "    mail_idRange = range(0,11)\n",
    "    user_idRange = range(0,11)\n",
    "    \n",
    "       \n",
    "    #last_online\n",
    "    dataframe.loc[ (dataframe.last_online.notnull()),'last_online']=dataframe['last_online'].dropna().map(lambda x:(datetime.datetime.today()-datetime.datetime.fromtimestamp(x)).days)\n",
    "    mean_last_online_days = dataframe.last_online.mean()\n",
    "    dataframe.loc[ (dataframe.last_online.isnull()), 'last_online'] = mean_last_online_days\n",
    "    dataframe = norm(dataframe,'last_online') \n",
    "    \n",
    "    #mail_type\n",
    "    mode_mail_type = dataframe.mail_type.dropna().mode().values\n",
    "    dataframe.loc[ (dataframe.mail_type.isnull()), 'mail_type'] = mode_mail_type\n",
    "    dataFrameMailTypesDiff = np.setdiff1d(mailTypes, np.unique(dataframe.mail_type)) \n",
    "    dummiesMail_type =  pd.get_dummies(dataframe.mail_type,prefix='col')\n",
    "    dataframe = pd.concat([dataframe, dummiesMail_type], axis=1)\n",
    "    for mailType in map(lambda x:\"col_\"+x,dataFrameMailTypesDiff):\n",
    "        dataframe = pd.concat([dataframe,pd.DataFrame({mailType: np.zeros(dataframe.shape[0])})],axis=1)\n",
    "    \n",
    "    #mail_category\n",
    "    mode_mail_category = dataframe.mail_category.dropna().mode().values\n",
    "    dataframe.loc[ (dataframe.mail_category.isnull()), 'mail_category'] = mode_mail_category\n",
    "    dataFrameMailCategoryDiff = np.setdiff1d(mailCategories, np.unique(dataframe.mail_category)) \n",
    "    dummiesMail_category =  pd.get_dummies(dataframe.mail_category,prefix='col')\n",
    "    dataframe = pd.concat([dataframe, dummiesMail_category], axis=1)\n",
    "    for mailCategoryItem in map(lambda x:\"col_\"+x,dataFrameMailCategoryDiff):\n",
    "        dataframe = pd.concat([dataframe,pd.DataFrame({mailCategoryItem: np.zeros(dataframe.shape[0])})],axis=1)\n",
    "    \n",
    "    #hacker_confirmation\n",
    "    dataframe['hacker_confirmation'] = dataframe.hacker_confirmation.map( {False: 0, True: 1} ).astype(int)\n",
    "    \n",
    "    #mail_id\n",
    "    dataTemp  = dataframe['mail_id'].value_counts()\n",
    "    hist, edges = np.histogram(dataTemp, bins=[ 1.00000000e+00,2.62150000e+03,5.24200000e+03,\n",
    "                                               7.86250000e+03,1.04830000e+04,1.31035000e+04,\n",
    "                                               1.57240000e+04,1.83445000e+04,2.09650000e+04,\n",
    "                                               2.35855000e+04,2.62060000e+04])\n",
    "    dataTempDict = dataTemp.to_dict()\n",
    "    dataframe['mail_id'] = dataframe['mail_id'].map(lambda x: [i for i,v in enumerate(edges) if v<=dataTempDict[x]][-1] )\n",
    "    dummiesMail_id =  pd.get_dummies(dataframe.mail_id,prefix='mail_id')\n",
    "    dataframe = pd.concat([dataframe, dummiesMail_id], axis=1)\n",
    "    #mail_id complete\n",
    "    dataFrameMailIdDiff = np.setdiff1d(mail_idRange, np.unique(dataframe.mail_id)) \n",
    "    for mailIdItem in map(lambda x:\"mail_id_\"+str(x),dataFrameMailIdDiff):\n",
    "        dataframe = pd.concat([dataframe,pd.DataFrame({mailIdItem: np.zeros(dataframe.shape[0])})],axis=1)\n",
    "    \n",
    "    #user_id \n",
    "    dataTemp  = dataframe['user_id'].value_counts()\n",
    "    hist, edges = np.histogram(dataTemp, bins=[1.,11.5,22.,32.5,43.,53.5,64.,74.5,85.,95.5,106.])\n",
    "    dataTempDict = dataTemp.to_dict()\n",
    "    dataframe['user_id'] = dataframe['user_id'].map(lambda x: [i for i,v in enumerate(edges) if v<=dataTempDict[x]][-1] )\n",
    "    dummiesUser_id =  pd.get_dummies(dataframe.user_id,prefix='user_id')\n",
    "    dataframe = pd.concat([dataframe, dummiesUser_id], axis=1)\n",
    "    #user_id complete\n",
    "    dataFrameUserIdDiff = np.setdiff1d(user_idRange, np.unique(dataframe.user_id)) \n",
    "    for userIdItem in map(lambda x:\"user_id_\"+str(x),dataFrameUserIdDiff):\n",
    "        dataframe = pd.concat([dataframe,pd.DataFrame({userIdItem: np.zeros(dataframe.shape[0])})],axis=1)\n",
    "    \n",
    "    #drop attributes\n",
    "    dataframe = dataframe.drop(['user_id',\n",
    "                                'mail_id',\n",
    "                                'hacker_created_at',\n",
    "                                'sent_time',\n",
    "                                'hacker_timezone',\n",
    "                                'mail_category',\n",
    "                                'mail_type',\n",
    "                                #'last_online'\n",
    "                               ], axis=1) \n",
    "    dataframe = dataframe.reindex_axis(sorted(dataframe.columns), axis=1)\n",
    "    if(train):\n",
    "        dataframe['opened'] = dataframe.clicked.map( {False: 0, True: 1} ).astype(int)\n",
    "        dataframe = dataframe.drop(['clicked','unsubscribed','open_time','click_time','unsubscribe_time'], axis=1) \n",
    "        dataframe = dataframe.reindex_axis(['opened'] + list([a for a in dataframe.columns if a != 'opened']), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#     dataframe = dataframe.drop([\n",
    "#                                 'contest_login_count',\n",
    "#                                 'contest_login_count_1_days',\n",
    "#                                 'contest_login_count_30_days',\n",
    "#                                 'contest_login_count_365_days',\n",
    "#                                 'contest_login_count_7_days'\n",
    "#                                 ], axis=1) \n",
    "    \n",
    "    dataframe = norm(dataframe,'contest_login_count') \n",
    "    dataframe = norm(dataframe,'contest_login_count_1_days') \n",
    "    dataframe = norm(dataframe,'contest_login_count_30_days') \n",
    "    dataframe = norm(dataframe,'contest_login_count_365_days') \n",
    "    dataframe = norm(dataframe,'contest_login_count_7_days') \n",
    "\n",
    "#     dataframe = dataframe.drop([\n",
    "#                                 'contest_participation_count',\n",
    "#                                 'contest_participation_count_1_days',\n",
    "#                                 'contest_participation_count_30_days',\n",
    "#                                 'contest_participation_count_365_days',\n",
    "#                                'contest_participation_count_7_days'\n",
    "#                                 ], axis=1) \n",
    "\n",
    "    dataframe = norm(dataframe,'contest_participation_count') \n",
    "    dataframe = norm(dataframe,'contest_participation_count_1_days') \n",
    "    dataframe = norm(dataframe,'contest_participation_count_30_days') \n",
    "    dataframe = norm(dataframe,'contest_participation_count_365_days') \n",
    "    dataframe = norm(dataframe,'contest_participation_count_7_days') \n",
    "\n",
    "#     dataframe = dataframe.drop([\n",
    "#                                 'submissions_count',\n",
    "#                                 'submissions_count_1_days',\n",
    "#                                 'submissions_count_30_days',\n",
    "#                                 'submissions_count_365_days',\n",
    "#                                 'submissions_count_7_days'\n",
    "#                                 ], axis=1) \n",
    "    \n",
    "    dataframe = norm(dataframe,'submissions_count') \n",
    "    dataframe = norm(dataframe,'submissions_count_1_days') \n",
    "    dataframe = norm(dataframe,'submissions_count_30_days') \n",
    "    dataframe = norm(dataframe,'submissions_count_365_days') \n",
    "    dataframe = norm(dataframe,'submissions_count_7_days') \n",
    "\n",
    "#     dataframe = dataframe.drop([\n",
    "#                                 'submissions_count_contest',\n",
    "#                                'submissions_count_contest_1_days',\n",
    "#                                'submissions_count_contest_30_days',\n",
    "#                                'submissions_count_contest_365_days',\n",
    "#                                'submissions_count_contest_7_days'\n",
    "#                                 ], axis=1) \n",
    "\n",
    "    dataframe = norm(dataframe,'submissions_count_contest') \n",
    "    dataframe = norm(dataframe,'submissions_count_contest_1_days') \n",
    "    dataframe = norm(dataframe,'submissions_count_contest_30_days') \n",
    "    dataframe = norm(dataframe,'submissions_count_contest_365_days') \n",
    "    dataframe = norm(dataframe,'submissions_count_contest_7_days') \n",
    "\n",
    "#     dataframe = dataframe.drop([\n",
    "#                             'submissions_count_master',\n",
    "#                             'submissions_count_master_1_days', \n",
    "#                             'submissions_count_master_30_days',\n",
    "#                             'submissions_count_master_365_days',\n",
    "#                             'submissions_count_master_7_days'\n",
    "#                             ], axis=1) \n",
    "\n",
    "    dataframe = norm(dataframe,'submissions_count_master') \n",
    "    dataframe = norm(dataframe,'submissions_count_master_1_days') \n",
    "    dataframe = norm(dataframe,'submissions_count_master_30_days') \n",
    "    dataframe = norm(dataframe,'submissions_count_master_365_days') \n",
    "    dataframe = norm(dataframe,'submissions_count_master_7_days') \n",
    "\n",
    "#     dataframe = dataframe.drop([\n",
    "#                             'forum_comments_count',\n",
    "#                             'forum_count',\n",
    "#                             'forum_expert_count',\n",
    "#                             'forum_questions_count'\n",
    "#                           ], axis=1) \n",
    "\n",
    "    dataframe = norm(dataframe,'forum_comments_count') \n",
    "    dataframe = norm(dataframe,'forum_count') \n",
    "    dataframe = norm(dataframe,'forum_expert_count') \n",
    "    dataframe = norm(dataframe,'forum_questions_count') \n",
    "\n",
    "#     dataframe = dataframe.drop([\n",
    "#                             'ipn_count',\n",
    "#                             'ipn_count_1_days',\n",
    "#                             'ipn_count_30_days',\n",
    "#                             'ipn_count_365_days',\n",
    "#                             'ipn_count_7_days'\n",
    "#                             ], axis=1) \n",
    "    dataframe = norm(dataframe,'ipn_count') \n",
    "    dataframe = norm(dataframe,'ipn_count_1_days') \n",
    "    dataframe = norm(dataframe,'ipn_count_30_days') \n",
    "    dataframe = norm(dataframe,'ipn_count_365_days') \n",
    "    dataframe = norm(dataframe,'ipn_count_7_days') \n",
    "\n",
    "#     dataframe = dataframe.drop([\n",
    "#                             'ipn_read',\n",
    "#                             'ipn_read_1_days',\n",
    "#                             'ipn_read_30_days',\n",
    "#                             'ipn_read_365_days',\n",
    "#                             'ipn_read_7_days'\n",
    "#                             ], axis=1) \n",
    "\n",
    "    dataframe = norm(dataframe,'ipn_read') \n",
    "    dataframe = norm(dataframe,'ipn_read_1_days') \n",
    "    dataframe = norm(dataframe,'ipn_read_30_days') \n",
    "    dataframe = norm(dataframe,'ipn_read_365_days') \n",
    "    dataframe = norm(dataframe,'ipn_read_7_days') \n",
    "\n",
    "\n",
    "    \n",
    "    return dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(486048, 54)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('training_dataset.csv/training_dataset.csv', header=0)  \n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(486048, 86)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = preProcessData(train_df)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.77072205e-03   3.71353814e-04   1.98180273e-04   1.80146950e-04\n",
      "   7.61782866e-04   2.48278918e-04   1.58089649e-03   2.12166263e-04\n",
      "   9.94859665e-05   1.58272930e-05   2.51441598e-04   7.04175771e-04\n",
      "   8.86748393e-04   2.01070738e-04   3.67067638e-04   4.72360506e-04\n",
      "   2.23181305e-04   3.04143819e-04   1.37541143e-03   2.51226130e-03\n",
      "   1.99672152e-03   7.21444779e-05   2.22854923e-02   1.70746653e-03\n",
      "   1.50077125e-02   2.36403382e-02   8.80359638e-03   2.70312148e-02\n",
      "   3.13085586e-03   1.98066122e-02   2.82454065e-02   1.30996485e-02\n",
      "   7.97463734e-03   9.04150731e-03   2.63412214e-03   3.52101446e-03\n",
      "   4.74070999e-03   4.85191169e-02   1.21734577e-02   4.48563303e-02\n",
      "   4.88919186e-02   2.57217576e-02   2.27838408e-02   3.33534436e-03\n",
      "   1.47313563e-02   2.23433071e-02   8.66583844e-03   1.53509575e-01\n",
      "   2.57340360e-03   2.79596478e-03   1.96168371e-03   2.30904352e-03\n",
      "   3.31781313e-03   7.44730736e-04   2.02896068e-03   7.10025619e-04\n",
      "   0.00000000e+00   0.00000000e+00   2.95514443e-03   3.95377030e-02\n",
      "   6.74257725e-03   3.13980951e-02   3.88212431e-02   2.47421003e-02\n",
      "   2.02355824e-02   2.27252420e-03   1.16215394e-02   1.96674656e-02\n",
      "   7.73677461e-03   3.95386701e-02   6.34551572e-03   3.16082659e-02\n",
      "   3.83494092e-02   2.48582418e-02   2.80121959e-03   4.19599550e-03\n",
      "   6.96835322e-05   3.61034900e-03   3.29745938e-03   2.72827831e-03\n",
      "   2.81237045e-03   2.18712090e-03   1.20704379e-03   1.21025402e-03\n",
      "   0.00000000e+00]\n",
      "(388838L, 26L)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "#from nolearn.dbn import DBN\n",
    "from sklearn import ensemble \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "train_data = train_df.values\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_data[0::,1::], train_data[0::,0], \n",
    "                            test_size = 0.2, random_state = 123) # Split training/test.\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(x_train, y_train)\n",
    "print(clf.feature_importances_)\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "x_train = model.transform(x_train)\n",
    "x_test = model.transform(x_test)\n",
    "print(x_train.shape)\n",
    "# hipotese = DBN([x_train.shape[1], 300, 2],\n",
    "#                 learn_rates = 0.01,\n",
    "#                 learn_rate_decays = 0.9,\n",
    "#                 epochs = 100,\n",
    "#                 dropouts = 0, # Express the percentage of nodes that will be randomly dropped as a decimal.\n",
    "#                 verbose = 1)\n",
    "#hipotese = linear_model.LogisticRegression(C=1e5)\n",
    "#hipotese = tree.DecisionTreeClassifier(random_state=1234)\n",
    "#hipotese = ensemble.RandomForestClassifier(random_state=1234)\n",
    "\n",
    "hipotese = svm.SVC()\n",
    "\n",
    "hipotese.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      1.00      0.97     91840\n",
      "        1.0       0.00      0.00      0.00      5370\n",
      "\n",
      "avg / total       0.89      0.94      0.92     97210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = y_test, hipotese.predict(x_test) # Get our predictions\n",
    "print(classification_report(y_true, y_pred)) # Classification on each digit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207424, 48)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test_dataset.csv/test_dataset.csv', header=0)  \n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207424, 85)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = preProcessData(test_df,False)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207424L, 26L)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = model.transform(test_df)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = test_df\n",
    "\n",
    "y_pred = hipotese.predict(test_data).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saveFileForSubmission(y_pred,'submissionSVMtWithFeatureSelection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
