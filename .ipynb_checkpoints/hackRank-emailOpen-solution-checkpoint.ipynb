{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import time\n",
    "from datetime import date\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "def saveFileForSubmission(predicted_lables,custonFileName='submission.csv',customHeader=''):\n",
    "    result = np.c_[predicted_lables]\n",
    "\n",
    "    np.savetxt(custonFileName, \n",
    "           result.astype(int), \n",
    "           delimiter=',', \n",
    "           header = customHeader, \n",
    "           comments = '', \n",
    "           fmt='%u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm(dataframe,variable):\n",
    "    mean = dataframe[variable].mean()\n",
    "    max_val = dataframe[variable].max()\n",
    "    min_val = dataframe[variable].min()\n",
    "    dataframe[variable] = dataframe[variable].apply(lambda x: (x - mean) / (max_val -min_val+0.0001))\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preProcessData(dataframe,train=True):\n",
    "    mailTypes = ['mail_type_1', 'mail_type_2', 'mail_type_3', 'mail_type_4']\n",
    "    mailCategories = ['mail_category_1', 'mail_category_10', 'mail_category_11',\n",
    "                    'mail_category_12', 'mail_category_13', 'mail_category_14',\n",
    "                    'mail_category_15', 'mail_category_16', 'mail_category_17',\n",
    "                    'mail_category_18', 'mail_category_2', 'mail_category_3',\n",
    "                    'mail_category_4', 'mail_category_5', 'mail_category_6',\n",
    "                    'mail_category_7', 'mail_category_8', 'mail_category_9']\n",
    "    mail_idRange = range(0,11)\n",
    "    user_idRange = range(0,11)\n",
    "    \n",
    "       \n",
    "    #last_online\n",
    "    dataframe.loc[ (dataframe.last_online.notnull()),'last_online']=dataframe['last_online'].dropna().map(lambda x:(datetime.datetime.today()-datetime.datetime.fromtimestamp(x)).days)\n",
    "    mean_last_online_days = dataframe.last_online.mean()\n",
    "    dataframe.loc[ (dataframe.last_online.isnull()), 'last_online'] = mean_last_online_days\n",
    "    dataframe = norm(dataframe,'last_online') \n",
    "    \n",
    "    #mail_type\n",
    "    mode_mail_type = dataframe.mail_type.dropna().mode().values\n",
    "    dataframe.loc[ (dataframe.mail_type.isnull()), 'mail_type'] = mode_mail_type\n",
    "    dataFrameMailTypesDiff = np.setdiff1d(mailTypes, np.unique(dataframe.mail_type)) \n",
    "    dummiesMail_type =  pd.get_dummies(dataframe.mail_type,prefix='col')\n",
    "    dataframe = pd.concat([dataframe, dummiesMail_type], axis=1)\n",
    "    for mailType in map(lambda x:\"col_\"+x,dataFrameMailTypesDiff):\n",
    "        dataframe = pd.concat([dataframe,pd.DataFrame({mailType: np.zeros(dataframe.shape[0])})],axis=1)\n",
    "    \n",
    "    #mail_category\n",
    "    mode_mail_category = dataframe.mail_category.dropna().mode().values\n",
    "    dataframe.loc[ (dataframe.mail_category.isnull()), 'mail_category'] = mode_mail_category\n",
    "    dataFrameMailCategoryDiff = np.setdiff1d(mailCategories, np.unique(dataframe.mail_category)) \n",
    "    dummiesMail_category =  pd.get_dummies(dataframe.mail_category,prefix='col')\n",
    "    dataframe = pd.concat([dataframe, dummiesMail_category], axis=1)\n",
    "    for mailCategoryItem in map(lambda x:\"col_\"+x,dataFrameMailCategoryDiff):\n",
    "        dataframe = pd.concat([dataframe,pd.DataFrame({mailCategoryItem: np.zeros(dataframe.shape[0])})],axis=1)\n",
    "    \n",
    "    #hacker_confirmation\n",
    "    dataframe['hacker_confirmation'] = dataframe.hacker_confirmation.map( {False: 0, True: 1} ).astype(int)\n",
    "    \n",
    "    #mail_id\n",
    "    dataTemp  = dataframe['mail_id'].value_counts()\n",
    "    hist, edges = np.histogram(dataTemp, bins=[ 1.00000000e+00,2.62150000e+03,5.24200000e+03,\n",
    "                                               7.86250000e+03,1.04830000e+04,1.31035000e+04,\n",
    "                                               1.57240000e+04,1.83445000e+04,2.09650000e+04,\n",
    "                                               2.35855000e+04,2.62060000e+04])\n",
    "    dataTempDict = dataTemp.to_dict()\n",
    "    dataframe['mail_id'] = dataframe['mail_id'].map(lambda x: [i for i,v in enumerate(edges) if v<=dataTempDict[x]][-1] )\n",
    "    dummiesMail_id =  pd.get_dummies(dataframe.mail_id,prefix='mail_id')\n",
    "    dataframe = pd.concat([dataframe, dummiesMail_id], axis=1)\n",
    "    #mail_id complete\n",
    "    dataFrameMailIdDiff = np.setdiff1d(mail_idRange, np.unique(dataframe.mail_id)) \n",
    "    for mailIdItem in map(lambda x:\"mail_id_\"+str(x),dataFrameMailIdDiff):\n",
    "        dataframe = pd.concat([dataframe,pd.DataFrame({mailIdItem: np.zeros(dataframe.shape[0])})],axis=1)\n",
    "    \n",
    "    #user_id \n",
    "    dataTemp  = dataframe['user_id'].value_counts()\n",
    "    hist, edges = np.histogram(dataTemp, bins=[1.,11.5,22.,32.5,43.,53.5,64.,74.5,85.,95.5,106.])\n",
    "    dataTempDict = dataTemp.to_dict()\n",
    "    dataframe['user_id'] = dataframe['user_id'].map(lambda x: [i for i,v in enumerate(edges) if v<=dataTempDict[x]][-1] )\n",
    "    dummiesUser_id =  pd.get_dummies(dataframe.user_id,prefix='user_id')\n",
    "    dataframe = pd.concat([dataframe, dummiesUser_id], axis=1)\n",
    "    #user_id complete\n",
    "    dataFrameUserIdDiff = np.setdiff1d(user_idRange, np.unique(dataframe.user_id)) \n",
    "    for userIdItem in map(lambda x:\"user_id_\"+str(x),dataFrameUserIdDiff):\n",
    "        dataframe = pd.concat([dataframe,pd.DataFrame({userIdItem: np.zeros(dataframe.shape[0])})],axis=1)\n",
    "    \n",
    "    #drop attributes\n",
    "    dataframe = dataframe.drop(['user_id',\n",
    "                                'mail_id',\n",
    "                                'hacker_created_at',\n",
    "                                'sent_time',\n",
    "                                'hacker_timezone',\n",
    "                                'mail_category',\n",
    "                                'mail_type',\n",
    "                                #'last_online'\n",
    "                               ], axis=1) \n",
    "    dataframe = dataframe.reindex_axis(sorted(dataframe.columns), axis=1)\n",
    "    if(train):\n",
    "        dataframe['opened'] = dataframe.clicked.map( {False: 0, True: 1} ).astype(int)\n",
    "        dataframe = dataframe.drop(['clicked','unsubscribed','open_time','click_time','unsubscribe_time'], axis=1) \n",
    "        dataframe = dataframe.reindex_axis(['opened'] + list([a for a in dataframe.columns if a != 'opened']), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#     dataframe = dataframe.drop([\n",
    "#                                 'contest_login_count',\n",
    "#                                 'contest_login_count_1_days',\n",
    "#                                 'contest_login_count_30_days',\n",
    "#                                 'contest_login_count_365_days',\n",
    "#                                 'contest_login_count_7_days'\n",
    "#                                 ], axis=1) \n",
    "    \n",
    "    dataframe = norm(dataframe,'contest_login_count') \n",
    "    dataframe = norm(dataframe,'contest_login_count_1_days') \n",
    "    dataframe = norm(dataframe,'contest_login_count_30_days') \n",
    "    dataframe = norm(dataframe,'contest_login_count_365_days') \n",
    "    dataframe = norm(dataframe,'contest_login_count_7_days') \n",
    "\n",
    "#     dataframe = dataframe.drop([\n",
    "#                                 'contest_participation_count',\n",
    "#                                 'contest_participation_count_1_days',\n",
    "#                                 'contest_participation_count_30_days',\n",
    "#                                 'contest_participation_count_365_days',\n",
    "#                                'contest_participation_count_7_days'\n",
    "#                                 ], axis=1) \n",
    "\n",
    "    dataframe = norm(dataframe,'contest_participation_count') \n",
    "    dataframe = norm(dataframe,'contest_participation_count_1_days') \n",
    "    dataframe = norm(dataframe,'contest_participation_count_30_days') \n",
    "    dataframe = norm(dataframe,'contest_participation_count_365_days') \n",
    "    dataframe = norm(dataframe,'contest_participation_count_7_days') \n",
    "\n",
    "#     dataframe = dataframe.drop([\n",
    "#                                 'submissions_count',\n",
    "#                                 'submissions_count_1_days',\n",
    "#                                 'submissions_count_30_days',\n",
    "#                                 'submissions_count_365_days',\n",
    "#                                 'submissions_count_7_days'\n",
    "#                                 ], axis=1) \n",
    "    \n",
    "    dataframe = norm(dataframe,'submissions_count') \n",
    "    dataframe = norm(dataframe,'submissions_count_1_days') \n",
    "    dataframe = norm(dataframe,'submissions_count_30_days') \n",
    "    dataframe = norm(dataframe,'submissions_count_365_days') \n",
    "    dataframe = norm(dataframe,'submissions_count_7_days') \n",
    "\n",
    "#     dataframe = dataframe.drop([\n",
    "#                                 'submissions_count_contest',\n",
    "#                                'submissions_count_contest_1_days',\n",
    "#                                'submissions_count_contest_30_days',\n",
    "#                                'submissions_count_contest_365_days',\n",
    "#                                'submissions_count_contest_7_days'\n",
    "#                                 ], axis=1) \n",
    "\n",
    "    dataframe = norm(dataframe,'submissions_count_contest') \n",
    "    dataframe = norm(dataframe,'submissions_count_contest_1_days') \n",
    "    dataframe = norm(dataframe,'submissions_count_contest_30_days') \n",
    "    dataframe = norm(dataframe,'submissions_count_contest_365_days') \n",
    "    dataframe = norm(dataframe,'submissions_count_contest_7_days') \n",
    "\n",
    "#     dataframe = dataframe.drop([\n",
    "#                             'submissions_count_master',\n",
    "#                             'submissions_count_master_1_days', \n",
    "#                             'submissions_count_master_30_days',\n",
    "#                             'submissions_count_master_365_days',\n",
    "#                             'submissions_count_master_7_days'\n",
    "#                             ], axis=1) \n",
    "\n",
    "    dataframe = norm(dataframe,'submissions_count_master') \n",
    "    dataframe = norm(dataframe,'submissions_count_master_1_days') \n",
    "    dataframe = norm(dataframe,'submissions_count_master_30_days') \n",
    "    dataframe = norm(dataframe,'submissions_count_master_365_days') \n",
    "    dataframe = norm(dataframe,'submissions_count_master_7_days') \n",
    "\n",
    "#     dataframe = dataframe.drop([\n",
    "#                             'forum_comments_count',\n",
    "#                             'forum_count',\n",
    "#                             'forum_expert_count',\n",
    "#                             'forum_questions_count'\n",
    "#                           ], axis=1) \n",
    "\n",
    "    dataframe = norm(dataframe,'forum_comments_count') \n",
    "    dataframe = norm(dataframe,'forum_count') \n",
    "    dataframe = norm(dataframe,'forum_expert_count') \n",
    "    dataframe = norm(dataframe,'forum_questions_count') \n",
    "\n",
    "#     dataframe = dataframe.drop([\n",
    "#                             'ipn_count',\n",
    "#                             'ipn_count_1_days',\n",
    "#                             'ipn_count_30_days',\n",
    "#                             'ipn_count_365_days',\n",
    "#                             'ipn_count_7_days'\n",
    "#                             ], axis=1) \n",
    "    dataframe = norm(dataframe,'ipn_count') \n",
    "    dataframe = norm(dataframe,'ipn_count_1_days') \n",
    "    dataframe = norm(dataframe,'ipn_count_30_days') \n",
    "    dataframe = norm(dataframe,'ipn_count_365_days') \n",
    "    dataframe = norm(dataframe,'ipn_count_7_days') \n",
    "\n",
    "#     dataframe = dataframe.drop([\n",
    "#                             'ipn_read',\n",
    "#                             'ipn_read_1_days',\n",
    "#                             'ipn_read_30_days',\n",
    "#                             'ipn_read_365_days',\n",
    "#                             'ipn_read_7_days'\n",
    "#                             ], axis=1) \n",
    "\n",
    "    dataframe = norm(dataframe,'ipn_read') \n",
    "    dataframe = norm(dataframe,'ipn_read_1_days') \n",
    "    dataframe = norm(dataframe,'ipn_read_30_days') \n",
    "    dataframe = norm(dataframe,'ipn_read_365_days') \n",
    "    dataframe = norm(dataframe,'ipn_read_7_days') \n",
    "\n",
    "\n",
    "    \n",
    "    return dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(486048, 54)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('training_dataset.csv/training_dataset.csv', header=0)  \n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1120, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 301, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 346, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\inspect.py\", line 1049, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"C:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\inspect.py\", line 1009, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\inspect.py\", line 454, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"C:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\inspect.py\", line 491, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\py\\_apipkg.py\", line 171, in __getattribute__\n",
      "    return getattr(getmod(), name)\n",
      "  File \"C:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\py\\_apipkg.py\", line 155, in getmod\n",
      "    x = importobj(modpath, None)\n",
      "  File \"C:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\py\\_apipkg.py\", line 48, in importobj\n",
      "    module = __import__(modpath, None, None, ['__doc__'])\n",
      "  File \"C:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pytest.py\", line 27, in <module>\n",
      "    _preloadplugins() # to populate pytest.* namespace so help(pytest) works\n",
      "  File \"C:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\_pytest\\config.py\", line 76, in _preloadplugins\n",
      "    _preinit.append(get_config())\n",
      "  File \"C:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\_pytest\\config.py\", line 85, in get_config\n",
      "    pluginmanager.import_plugin(spec)\n",
      "  File \"C:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\_pytest\\config.py\", line 385, in import_plugin\n",
      "    __import__(importspec)\n",
      "  File \"C:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\_pytest\\main.py\", line 16, in <module>\n",
      "    from _pytest.runner import collect_one_node\n",
      "  File \"C:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\_pytest\\runner.py\", line 69, in <module>\n",
      "    def runtestprotocol(item, log=True, nextitem=None):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[0;32m   1828\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1829\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 1830\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   1831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1832\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\IPython\\core\\ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1392\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1393\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1394\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\IPython\\core\\ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1300\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1301\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1302\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1303\u001b[0m             )\n\u001b[0;32m   1304\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\alvaro.joao.silvino\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\IPython\\core\\ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1184\u001b[0m                 \u001b[0mstructured_traceback_parts\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m             \u001b[0mstructured_traceback_parts\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstructured_traceback_parts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "train_df = preProcessData(train_df)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from nolearn.dbn import DBN\n",
    "from sklearn import ensemble \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "train_data = train_df.values\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_data[0::,1::], train_data[0::,0], \n",
    "                            test_size = 0.2, random_state = 123) # Split training/test.\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(x_train, y_train)\n",
    "print(clf.feature_importances_)\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "x_train = model.transform(x_train)\n",
    "x_test = model.transform(x_test)\n",
    "\n",
    "# hipotese = DBN([x_train.shape[1], 300, 2],\n",
    "#                 learn_rates = 0.01,\n",
    "#                 learn_rate_decays = 0.9,\n",
    "#                 epochs = 100,\n",
    "#                 dropouts = 0, # Express the percentage of nodes that will be randomly dropped as a decimal.\n",
    "#                 verbose = 1)\n",
    "#hipotese = linear_model.LogisticRegression(C=1e5)\n",
    "#hipotese = tree.DecisionTreeClassifier(random_state=1234)\n",
    "hipotese = ensemble.RandomForestClassifier(random_state=1234)\n",
    "\n",
    "#hipotese = svm.SVC()\n",
    "\n",
    "hipotese.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test, hipotese.predict(x_test) # Get our predictions\n",
    "print(classification_report(y_true, y_pred)) # Classification on each digit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207424, 48)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test_dataset.csv/test_dataset.csv', header=0)  \n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207424, 40)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = preProcessData(test_df,False)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = test_df.values\n",
    "\n",
    "y_pred = hipotese.predict(test_data).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saveFileForSubmission(y_pred,'submissionRandomForest2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
